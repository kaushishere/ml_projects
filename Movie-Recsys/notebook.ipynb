{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760344ba",
   "metadata": {},
   "source": [
    "# About"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2432ddbf",
   "metadata": {},
   "source": [
    "Movie Lens 100k dataset <br>\n",
    "\n",
    "In this notebook, we explore two approaches to predicting movie ratings.\n",
    "- The first is **collaborative filtering**, where we artificially initalise random movie/user feature vectors. Then, we train these feature vectors using our cost objective of reducing the squared error between prediction and actual rating (plus regularisation). This method is expected to yield poorer accuracies in comparison to the second method.\n",
    "- **Content-based filtering** is where we start with defined movie/user features and then train both a movie network and user network to extract meaningful movie/user feature vectors that aid in minimising the cost objective - squared error between predicted and actual values (plus regularisation). In this method, we use user-related information such as occupation/genre and movie-related information such as genre breakdown to yield more accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1389c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tabulate\n",
    "from helpers import *\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "from helpers import *\n",
    "from variables import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc082d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_as_table(data,headers,top_n_rows=5):\n",
    "    \"\"\"\n",
    "    Uses the tabulate module to print array data in a tabular format\n",
    "    \"\"\"\n",
    "    table = tabulate.tabulate(data[:top_n_rows],\n",
    "                              headers=headers,\n",
    "                              tablefmt=\"fancy_grid\",\n",
    "                              numalign=\"right\",\n",
    "                              stralign=\"center\",\n",
    "                              colalign=(\"center\", \"center\", \"right\"))\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0991a7e3",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96093acd",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f405023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape: (1682, 943)\n",
      "R shape: (1682, 943)\n",
      "Average rating for movie 31 is 0.3255567338282078\n",
      "Average rating for movie 107 is 0.21208907741251326\n",
      "Average rating for movie 1447 is 0.01166489925768823\n",
      "Average rating for movie 227 is 0.9872746553552492\n",
      "Average rating for movie 1367 is 0.02332979851537646\n"
     ]
    }
   ],
   "source": [
    "Y,R,movie_mapping = loadDataCollaborativeFiltering()\n",
    "print(\"Y shape:\", Y.shape)\n",
    "print(\"R shape:\", R.shape)\n",
    "for i in np.random.randint(0,Y.shape[0],5):\n",
    "    print(f\"Average rating for movie {i} is {np.average(Y[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ba4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalise ratings by subtracting mean rating for every movie so that mean rating for each movie~0\n",
    "Ynorm,Ymean = normaliseRatings(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefb4590",
   "metadata": {},
   "source": [
    "## Define Cost Objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a5a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcCostObjective(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Calculates the Cost Objective according the squared error function and regularisation\n",
    "\n",
    "    X: movie features vector (num_movies, num_features)\n",
    "    W: user features vector (num_users, num_features)\n",
    "    b: user bias vector (num_users,)\n",
    "    Y: ratings matrix (num_movies, num_users)\n",
    "    R: indicator matrix for ratings (num_movies, num_users)\n",
    "    lambda_: regularization parameter\n",
    "    \"\"\"\n",
    "    # Predicted ratings\n",
    "    j = (tf.matmul(X, tf.transpose(W))+b-Y)*R\n",
    "\n",
    "    # Compute the cost\n",
    "    cost = 0.5 * tf.reduce_sum(j**2)\n",
    "\n",
    "    # Add regularization terms\n",
    "    cost += (lambda_ / 2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78550f",
   "metadata": {},
   "source": [
    "## Build & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ad94398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model parameters\n",
    "num_features = 100\n",
    "num_movies = Y.shape[0]\n",
    "num_users = Y.shape[1]\n",
    "\n",
    "# randomly initalise movie and user feature vectors\n",
    "X = tf.Variable(tf.random.uniform((num_movies,num_features)))\n",
    "W = tf.Variable(tf.random.uniform((num_users,num_features)))\n",
    "b = tf.Variable(tf.random.uniform((num_users,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss at iteration 0: 4888692.50 \n",
      "Training loss at iteration 100: 1181118.88 \n",
      "Training loss at iteration 200: 382624.03 \n",
      "Training loss at iteration 300: 179562.73 \n",
      "Training loss at iteration 400: 117144.17 \n",
      "Training loss at iteration 500: 93589.85 \n",
      "Training loss at iteration 600: 82242.39 \n",
      "Training loss at iteration 700: 75319.00 \n",
      "Training loss at iteration 800: 70298.96 \n",
      "Training loss at iteration 900: 66241.76 \n",
      "Training loss at iteration 1000: 62738.40 \n",
      "Training loss at iteration 1100: 59591.98 \n",
      "Training loss at iteration 1200: 56703.28 \n",
      "Training loss at iteration 1300: 54020.71 \n",
      "Training loss at iteration 1400: 51515.67 \n",
      "Training loss at iteration 1500: 49170.25 \n",
      "Training loss at iteration 1600: 46971.32 \n",
      "Training loss at iteration 1700: 44907.84 \n",
      "Training loss at iteration 1800: 42969.78 \n",
      "Training loss at iteration 1900: 41147.70 \n"
     ]
    }
   ],
   "source": [
    "# define training hyperparameters\n",
    "iters = 2000\n",
    "lambda_ = 1\n",
    "\n",
    "# train\n",
    "train_cf_model(X,W,b,Ynorm,R,calcCostObjective,lambda_,iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc3122",
   "metadata": {},
   "source": [
    "Compare predicted vs actual ratings for random movies that user 34 has rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8f3526a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 34's ratings:\n",
      "\n",
      "Movie 326: Predicted Rating 2.9 Actual Rating 3.0\n",
      "Movie 258: Predicted Rating 2.8 Actual Rating 4.0\n",
      "Movie 327: Predicted Rating 1.8 Actual Rating 3.0\n",
      "Movie 325: Predicted Rating 2.3 Actual Rating 3.0\n",
      "Movie 677: Predicted Rating 2.4 Actual Rating 3.0\n",
      "Movie 679: Predicted Rating 3.3 Actual Rating 4.0\n",
      "Movie 320: Predicted Rating 2.8 Actual Rating 3.0\n",
      "Movie 875: Predicted Rating 1.8 Actual Rating 2.0\n",
      "Movie 878: Predicted Rating 2.9 Actual Rating 4.0\n",
      "Movie 325: Predicted Rating 2.3 Actual Rating 3.0\n"
     ]
    }
   ],
   "source": [
    "# predictions\n",
    "p = (tf.matmul(X,tf.transpose(W)) + b)[:,34]\n",
    "# actual ratings\n",
    "r = Y[:,34]\n",
    "\n",
    "# mask for movies that user 34 has actually rated\n",
    "mask = R[:,34]!=0\n",
    "# get indices of movies rated by user 34\n",
    "rated_indices = np.where(mask)\n",
    "\n",
    "print(\"User 34's ratings:\\n\")\n",
    "for midx in np.random.choice(rated_indices[0],10):\n",
    "    print(f\"Movie {midx}: Predicted Rating {p[midx]:.1f} Actual Rating {r[midx]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561e5e2",
   "metadata": {},
   "source": [
    "# Content-Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221e7d0",
   "metadata": {},
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35e95f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw movie/user features\n",
    "movie_raw_features,user_raw_features = load_raw_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b89e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤═══════════════════╤════════════════╤══════════════════════╤════════════════════════════════════════════════════════╤═══════════╤══════════╤═════════════╤═════════════╤══════════════╤══════════╤═════════╤═══════════════╤═════════╤═══════════╤═════════════╤══════════╤═══════════╤═══════════╤═══════════╤══════════╤════════════╤═══════╤═══════════╕\n",
      "│  movie id  │    movie title    │   release date │  video release date  │                        IMDb URL                        │   unknown │   Action │   Adventure │   Animation │   Children's │   Comedy │   Crime │   Documentary │   Drama │   Fantasy │   Film-Noir │   Horror │   Musical │   Mystery │   Romance │   Sci-Fi │   Thriller │   War │   Western │\n",
      "╞════════════╪═══════════════════╪════════════════╪══════════════════════╪════════════════════════════════════════════════════════╪═══════════╪══════════╪═════════════╪═════════════╪══════════════╪══════════╪═════════╪═══════════════╪═════════╪═══════════╪═════════════╪══════════╪═══════════╪═══════════╪═══════════╪══════════╪════════════╪═══════╪═══════════╡\n",
      "│     1      │ Toy Story (1995)  │    01-Jan-1995 │                      │ http://us.imdb.com/M/title-exact?Toy%20Story%20(1995)  │         0 │        0 │           0 │           1 │            1 │        1 │       0 │             0 │       0 │         0 │           0 │        0 │         0 │         0 │         0 │        0 │          0 │     0 │         0 │\n",
      "├────────────┼───────────────────┼────────────────┼──────────────────────┼────────────────────────────────────────────────────────┼───────────┼──────────┼─────────────┼─────────────┼──────────────┼──────────┼─────────┼───────────────┼─────────┼───────────┼─────────────┼──────────┼───────────┼───────────┼───────────┼──────────┼────────────┼───────┼───────────┤\n",
      "│     2      │ GoldenEye (1995)  │    01-Jan-1995 │                      │  http://us.imdb.com/M/title-exact?GoldenEye%20(1995)   │         0 │        1 │           1 │           0 │            0 │        0 │       0 │             0 │       0 │         0 │           0 │        0 │         0 │         0 │         0 │        0 │          1 │     0 │         0 │\n",
      "├────────────┼───────────────────┼────────────────┼──────────────────────┼────────────────────────────────────────────────────────┼───────────┼──────────┼─────────────┼─────────────┼──────────────┼──────────┼─────────┼───────────────┼─────────┼───────────┼─────────────┼──────────┼───────────┼───────────┼───────────┼──────────┼────────────┼───────┼───────────┤\n",
      "│     3      │ Four Rooms (1995) │    01-Jan-1995 │                      │ http://us.imdb.com/M/title-exact?Four%20Rooms%20(1995) │         0 │        0 │           0 │           0 │            0 │        0 │       0 │             0 │       0 │         0 │           0 │        0 │         0 │         0 │         0 │        0 │          1 │     0 │         0 │\n",
      "├────────────┼───────────────────┼────────────────┼──────────────────────┼────────────────────────────────────────────────────────┼───────────┼──────────┼─────────────┼─────────────┼──────────────┼──────────┼─────────┼───────────────┼─────────┼───────────┼─────────────┼──────────┼───────────┼───────────┼───────────┼──────────┼────────────┼───────┼───────────┤\n",
      "│     4      │ Get Shorty (1995) │    01-Jan-1995 │                      │ http://us.imdb.com/M/title-exact?Get%20Shorty%20(1995) │         0 │        1 │           0 │           0 │            0 │        1 │       0 │             0 │       1 │         0 │           0 │        0 │         0 │         0 │         0 │        0 │          0 │     0 │         0 │\n",
      "├────────────┼───────────────────┼────────────────┼──────────────────────┼────────────────────────────────────────────────────────┼───────────┼──────────┼─────────────┼─────────────┼──────────────┼──────────┼─────────┼───────────────┼─────────┼───────────┼─────────────┼──────────┼───────────┼───────────┼───────────┼──────────┼────────────┼───────┼───────────┤\n",
      "│     5      │  Copycat (1995)   │    01-Jan-1995 │                      │   http://us.imdb.com/M/title-exact?Copycat%20(1995)    │         0 │        0 │           0 │           0 │            0 │        0 │       1 │             0 │       1 │         0 │           0 │        0 │         0 │         0 │         0 │        0 │          1 │     0 │         0 │\n",
      "╘════════════╧═══════════════════╧════════════════╧══════════════════════╧════════════════════════════════════════════════════════╧═══════════╧══════════╧═════════════╧═════════════╧══════════════╧══════════╧═════════╧═══════════════╧═════════╧═══════════╧═════════════╧══════════╧═══════════╧═══════════╧═══════════╧══════════╧════════════╧═══════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "# show movie features\n",
    "print_as_table(movie_raw_features,movie_raw_features_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a563644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([''], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['video release date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd9ffa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1995\n",
       "1       1995\n",
       "2       1995\n",
       "3       1995\n",
       "4       1995\n",
       "        ... \n",
       "1677    1998\n",
       "1678    1998\n",
       "1679    1998\n",
       "1680    1994\n",
       "1681    1996\n",
       "Name: release date, Length: 1682, dtype: Int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(movie_raw_features,columns=movie_raw_features_headers)\n",
    "df['Release Year']=pd.to_datetime(df['release date']).dt.year.astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b475a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═══════╤══════════╤══════════════╤════════════╕\n",
      "│  user id  │  age  │   gender │  occupation  │   zip code │\n",
      "╞═══════════╪═══════╪══════════╪══════════════╪════════════╡\n",
      "│     1     │  24   │        M │  technician  │      85711 │\n",
      "├───────────┼───────┼──────────┼──────────────┼────────────┤\n",
      "│     2     │  53   │        F │    other     │      94043 │\n",
      "├───────────┼───────┼──────────┼──────────────┼────────────┤\n",
      "│     3     │  23   │        M │    writer    │      32067 │\n",
      "├───────────┼───────┼──────────┼──────────────┼────────────┤\n",
      "│     4     │  24   │        M │  technician  │      43537 │\n",
      "├───────────┼───────┼──────────┼──────────────┼────────────┤\n",
      "│     5     │  33   │        F │    other     │      15213 │\n",
      "╘═══════════╧═══════╧══════════╧══════════════╧════════════╛\n"
     ]
    }
   ],
   "source": [
    "# show user features\n",
    "print_as_table(user_raw_features,user_raw_features_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e9d33958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤════════════════════════════╤═════════════════════════════════════════════════════════════════════╤═══════════╤══════════╤═════════════╤═════════════╤══════════════╤══════════╤═════════╤═══════════════╤═════════╤═══════════╤═════════════╤══════════╤═══════════╤═══════════╤═══════════╤══════════╤════════════╤═══════╤═══════════╤════════════════╤══════════════╕\n",
      "│  movie id  │        movie title         │                                                            IMDb URL │   unknown │   Action │   Adventure │   Animation │   Children's │   Comedy │   Crime │   Documentary │   Drama │   Fantasy │   Film-Noir │   Horror │   Musical │   Mystery │   Romance │   Sci-Fi │   Thriller │   War │   Western │   Release Year │   avg rating │\n",
      "╞════════════╪════════════════════════════╪═════════════════════════════════════════════════════════════════════╪═══════════╪══════════╪═════════════╪═════════════╪══════════════╪══════════╪═════════╪═══════════════╪═════════╪═══════════╪═════════════╪══════════╪═══════════╪═══════════╪═══════════╪══════════╪════════════╪═══════╪═══════════╪════════════════╪══════════════╡\n",
      "│    242     │        Kolya (1996)        │                     http://us.imdb.com/M/title-exact?Kolya%20(1996) │         0 │        0 │           0 │           0 │            0 │        1 │       0 │             0 │       0 │         0 │           0 │        0 │         0 │         0 │         0 │        0 │          0 │     0 │         0 │           1997 │      3.99145 │\n",
      "├────────────┼────────────────────────────┼─────────────────────────────────────────────────────────────────────┼───────────┼──────────┼─────────────┼─────────────┼──────────────┼──────────┼─────────┼───────────────┼─────────┼───────────┼─────────────┼──────────┼───────────┼───────────┼───────────┼──────────┼────────────┼───────┼───────────┼────────────────┼──────────────┤\n",
      "│    302     │  L.A. Confidential (1997)  │       http://us.imdb.com/M/title-exact?L%2EA%2E+Confidential+(1997) │         0 │        0 │           0 │           0 │            0 │        0 │       1 │             0 │       0 │         0 │           1 │        0 │         0 │         1 │         0 │        0 │          1 │     0 │         0 │           1997 │      4.16162 │\n",
      "├────────────┼────────────────────────────┼─────────────────────────────────────────────────────────────────────┼───────────┼──────────┼─────────────┼─────────────┼──────────────┼──────────┼─────────┼───────────────┼─────────┼───────────┼─────────────┼──────────┼───────────┼───────────┼───────────┼──────────┼────────────┼───────┼───────────┼────────────────┼──────────────┤\n",
      "│    377     │    Heavyweights (1994)     │              http://us.imdb.com/M/title-exact?Heavyweights%20(1994) │         0 │        0 │           0 │           0 │            1 │        1 │       0 │             0 │       0 │         0 │           0 │        0 │         0 │         0 │         0 │        0 │          0 │     0 │         0 │           1994 │      2.15385 │\n",
      "├────────────┼────────────────────────────┼─────────────────────────────────────────────────────────────────────┼───────────┼──────────┼─────────────┼─────────────┼──────────────┼──────────┼─────────┼───────────────┼─────────┼───────────┼─────────────┼──────────┼───────────┼───────────┼───────────┼──────────┼────────────┼───────┼───────────┼────────────────┼──────────────┤\n",
      "│     51     │ Legends of the Fall (1994) │ http://us.imdb.com/M/title-exact?Legends%20of%20the%20Fall%20(1994) │         0 │        0 │           0 │           0 │            0 │        0 │       0 │             0 │       1 │         0 │           0 │        0 │         0 │         0 │         1 │        0 │          0 │     1 │         1 │           1994 │      3.45679 │\n",
      "├────────────┼────────────────────────────┼─────────────────────────────────────────────────────────────────────┼───────────┼──────────┼─────────────┼─────────────┼──────────────┼──────────┼─────────┼───────────────┼─────────┼───────────┼─────────────┼──────────┼───────────┼───────────┼───────────┼──────────┼────────────┼───────┼───────────┼────────────────┼──────────────┤\n",
      "│    346     │    Jackie Brown (1997)     │                  http://us.imdb.com/M/title-exact?imdb-title-119396 │         0 │        0 │           0 │           0 │            0 │        0 │       1 │             0 │       1 │         0 │           0 │        0 │         0 │         0 │         0 │        0 │          0 │     0 │         0 │           1997 │      3.64286 │\n",
      "╘════════════╧════════════════════════════╧═════════════════════════════════════════════════════════════════════╧═══════════╧══════════╧═════════════╧═════════════╧══════════════╧══════════╧═════════╧═══════════════╧═════════╧═══════════╧═════════════╧══════════╧═══════════╧═══════════╧═══════════╧══════════╧════════════╧═══════╧═══════════╧════════════════╧══════════════╛\n",
      "╒═══════════╤════════════╤═══════╤══════════╤════════╤═════════════════╤══════════╤══════════╤════════════╤════════════╤═════════════════╤═════════════╤══════════════╤═════════════╤══════════╤═════════════╤═════════════╤════════╤═════════╤══════════════╤═══════════╤════════════╤═════════════╤═══════════╤══════════════╤══════════╕\n",
      "│  user id  │  zip code  │   age │   female │   male │   administrator │   artist │   doctor │   educator │   engineer │   entertainment │   executive │   healthcare │   homemaker │   lawyer │   librarian │   marketing │   none │   other │   programmer │   retired │   salesman │   scientist │   student │   technician │   writer │\n",
      "╞═══════════╪════════════╪═══════╪══════════╪════════╪═════════════════╪══════════╪══════════╪════════════╪════════════╪═════════════════╪═════════════╪══════════════╪═════════════╪══════════╪═════════════╪═════════════╪════════╪═════════╪══════════════╪═══════════╪════════════╪═════════════╪═══════════╪══════════════╪══════════╡\n",
      "│    196    │   55105    │    49 │        0 │      1 │               0 │        0 │        0 │          0 │          0 │               0 │           0 │            0 │           0 │        0 │           0 │           0 │      0 │       0 │            0 │         0 │          0 │           0 │         0 │            0 │        1 │\n",
      "├───────────┼────────────┼───────┼──────────┼────────┼─────────────────┼──────────┼──────────┼────────────┼────────────┼─────────────────┼─────────────┼──────────────┼─────────────┼──────────┼─────────────┼─────────────┼────────┼─────────┼──────────────┼───────────┼────────────┼─────────────┼───────────┼──────────────┼──────────┤\n",
      "│    186    │   00000    │    39 │        1 │      0 │               0 │        0 │        0 │          0 │          0 │               0 │           1 │            0 │           0 │        0 │           0 │           0 │      0 │       0 │            0 │         0 │          0 │           0 │         0 │            0 │        0 │\n",
      "├───────────┼────────────┼───────┼──────────┼────────┼─────────────────┼──────────┼──────────┼────────────┼────────────┼─────────────────┼─────────────┼──────────────┼─────────────┼──────────┼─────────────┼─────────────┼────────┼─────────┼──────────────┼───────────┼────────────┼─────────────┼───────────┼──────────────┼──────────┤\n",
      "│    22     │   40206    │    25 │        0 │      1 │               0 │        0 │        0 │          0 │          0 │               0 │           0 │            0 │           0 │        0 │           0 │           0 │      0 │       0 │            0 │         0 │          0 │           0 │         0 │            0 │        1 │\n",
      "├───────────┼────────────┼───────┼──────────┼────────┼─────────────────┼──────────┼──────────┼────────────┼────────────┼─────────────────┼─────────────┼──────────────┼─────────────┼──────────┼─────────────┼─────────────┼────────┼─────────┼──────────────┼───────────┼────────────┼─────────────┼───────────┼──────────────┼──────────┤\n",
      "│    244    │   80525    │    28 │        0 │      1 │               0 │        0 │        0 │          0 │          0 │               0 │           0 │            0 │           0 │        0 │           0 │           0 │      0 │       0 │            0 │         0 │          0 │           0 │         0 │            1 │        0 │\n",
      "├───────────┼────────────┼───────┼──────────┼────────┼─────────────────┼──────────┼──────────┼────────────┼────────────┼─────────────────┼─────────────┼──────────────┼─────────────┼──────────┼─────────────┼─────────────┼────────┼─────────┼──────────────┼───────────┼────────────┼─────────────┼───────────┼──────────────┼──────────┤\n",
      "│    166    │   55113    │    47 │        0 │      1 │               0 │        0 │        0 │          1 │          0 │               0 │           0 │            0 │           0 │        0 │           0 │           0 │      0 │       0 │            0 │         0 │          0 │           0 │         0 │            0 │        0 │\n",
      "╘═══════════╧════════════╧═══════╧══════════╧════════╧═════════════════╧══════════╧══════════╧════════════╧════════════╧═════════════════╧═════════════╧══════════════╧═════════════╧══════════╧═════════════╧═════════════╧════════╧═════════╧══════════════╧═══════════╧════════════╧═════════════╧═══════════╧══════════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "# we need to process the raw features so that there are no non-numerical values\n",
    "# i have done this in the eda_notebook so please check that out. here we will simply load in the arrays\n",
    "movie_features,movie_features_headers,user_features,user_features_headers = load_cleaned_features()\n",
    "targets = np.load(\"cleaned_data/targets.npy\",allow_pickle=True)[...,np.newaxis]\n",
    "\n",
    "# show cleaned movie features\n",
    "print_as_table(movie_features,movie_features_headers)\n",
    "# show cleaned user features\n",
    "print_as_table(user_features,user_features_headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b882be2",
   "metadata": {},
   "source": [
    "We will not be using the following features during training:\n",
    "- Movie features: movie id, movie title, IMDB URL\n",
    "- User features: user id, zip code (although potentially useful)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed73fe0",
   "metadata": {},
   "source": [
    "## Standardisation and train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d58f95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model will train better if we have scaled features/targets to have mean of 0 and variance of 1\n",
    "scalerMovies = StandardScaler()\n",
    "movie_train = scalerMovies.fit_transform(movie_features[:,3:])\n",
    "\n",
    "scalerUsers = StandardScaler()\n",
    "user_train = scalerUsers.fit_transform(user_features[:,2:])\n",
    "\n",
    "scalerTargets = StandardScaler()\n",
    "targets_train = scalerTargets.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "61227773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒════════════╤═══════════╤═════════════╤═════════════╤══════════════╤═══════════╤═══════════╤═══════════════╤═══════════╤═══════════╤═════════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤════════════╤═══════════╤═══════════╤════════════════╤══════════════╕\n",
      "│  unknown   │  Action   │   Adventure │   Animation │   Children's │    Comedy │     Crime │   Documentary │     Drama │   Fantasy │   Film-Noir │    Horror │   Musical │   Mystery │   Romance │    Sci-Fi │   Thriller │       War │   Western │   Release Year │   avg rating │\n",
      "╞════════════╪═══════════╪═════════════╪═════════════╪══════════════╪═══════════╪═══════════╪═══════════════╪═══════════╪═══════════╪═════════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪════════════╪═══════════╪═══════════╪════════════════╪══════════════╡\n",
      "│ -0.0100005 │ -0.586419 │   -0.399325 │   -0.193386 │    -0.278168 │   1.53366 │ -0.295984 │    -0.0873951 │ -0.814712 │  -0.11707 │   -0.132799 │ -0.236972 │ -0.228303 │ -0.235273 │ -0.491563 │ -0.381928 │  -0.529104 │ -0.322069 │ -0.137442 │       0.638891 │     0.893332 │\n",
      "├────────────┼───────────┼─────────────┼─────────────┼──────────────┼───────────┼───────────┼───────────────┼───────────┼───────────┼─────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼────────────┼───────────┼───────────┼────────────────┼──────────────┤\n",
      "│ -0.0100005 │ -0.586419 │   -0.399325 │   -0.193386 │    -0.278168 │ -0.652036 │   3.37856 │    -0.0873951 │ -0.814712 │  -0.11707 │     7.53017 │ -0.236972 │ -0.228303 │   4.25039 │ -0.491563 │ -0.381928 │    1.88999 │ -0.322069 │ -0.137442 │       0.638891 │      1.22265 │\n",
      "├────────────┼───────────┼─────────────┼─────────────┼──────────────┼───────────┼───────────┼───────────────┼───────────┼───────────┼─────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼────────────┼───────────┼───────────┼────────────────┼──────────────┤\n",
      "│ -0.0100005 │ -0.586419 │   -0.399325 │   -0.193386 │      3.59495 │   1.53366 │ -0.295984 │    -0.0873951 │ -0.814712 │  -0.11707 │   -0.132799 │ -0.236972 │ -0.228303 │ -0.235273 │ -0.491563 │ -0.381928 │  -0.529104 │ -0.322069 │ -0.137442 │       0.426958 │     -2.66303 │\n",
      "├────────────┼───────────┼─────────────┼─────────────┼──────────────┼───────────┼───────────┼───────────────┼───────────┼───────────┼─────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼────────────┼───────────┼───────────┼────────────────┼──────────────┤\n",
      "│ -0.0100005 │ -0.586419 │   -0.399325 │   -0.193386 │    -0.278168 │ -0.652036 │ -0.295984 │    -0.0873951 │   1.22743 │  -0.11707 │   -0.132799 │ -0.236972 │ -0.228303 │ -0.235273 │   2.03433 │ -0.381928 │  -0.529104 │   3.10493 │   7.27581 │       0.426958 │    -0.141414 │\n",
      "├────────────┼───────────┼─────────────┼─────────────┼──────────────┼───────────┼───────────┼───────────────┼───────────┼───────────┼─────────────┼───────────┼───────────┼───────────┼───────────┼───────────┼────────────┼───────────┼───────────┼────────────────┼──────────────┤\n",
      "│ -0.0100005 │ -0.586419 │   -0.399325 │   -0.193386 │    -0.278168 │ -0.652036 │   3.37856 │    -0.0873951 │   1.22743 │  -0.11707 │   -0.132799 │ -0.236972 │ -0.228303 │ -0.235273 │ -0.491563 │ -0.381928 │  -0.529104 │ -0.322069 │ -0.137442 │       0.638891 │     0.218686 │\n",
      "╘════════════╧═══════════╧═════════════╧═════════════╧══════════════╧═══════════╧═══════════╧═══════════════╧═══════════╧═══════════╧═════════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧════════════╧═══════════╧═══════════╧════════════════╧══════════════╛\n"
     ]
    }
   ],
   "source": [
    "# visualise scaled feature values\n",
    "print_as_table(movie_train,movie_features_headers[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2e5ccb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie training data shape:  (80000, 21)\n",
      "Movie test data shape:  (20000, 21)\n",
      "User training data shape:  (80000, 24)\n",
      "User test data shape:  (20000, 24)\n",
      "Targets training data shape:  (80000, 1)\n",
      "Targets test data shape:  (20000, 1)\n"
     ]
    }
   ],
   "source": [
    "# train-test split: 80-20\n",
    "movie_train,movie_test, user_train,user_test, targets_train,targets_test =train_test_split(movie_train,user_train,targets_train,test_size=0.2, shuffle=True)\n",
    "print(\"Movie training data shape: \",movie_train.shape)\n",
    "print(\"Movie test data shape: \",movie_test.shape)\n",
    "print(\"User training data shape: \",user_train.shape)\n",
    "print(\"User test data shape: \",user_test.shape)\n",
    "print(\"Targets training data shape: \",targets_train.shape)\n",
    "print(\"Targets test data shape: \",targets_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c400517",
   "metadata": {},
   "source": [
    "## Build and Train Networks\n",
    "There will be a movie network that creates movie vectors for each set of movie features we feed and a separate user network that creates user vectors for each set of user features we feed. I will be using the architecture from Andrew Ng's Recommender Systems class for both networks. The output of these networks will be a 32D vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "087921d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">42,656</span> │ input_layer_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,424</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lambda_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ lambda_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_8       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m42,656\u001b[0m │ input_layer_8[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m43,424\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_4 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda_5 (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ sequential_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_6 (\u001b[38;5;33mDot\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ lambda_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ lambda_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,080</span> (336.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m86,080\u001b[0m (336.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,080</span> (336.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m86,080\u001b[0m (336.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_outputs = 32\n",
    "movie_NN = tf.keras.models.Sequential([   \n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dense(128,activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "# forward pass in movieNN\n",
    "input_movie = tf.keras.Input(shape=(movie_train.shape[1],))\n",
    "vm = movie_NN(input_movie)\n",
    "vm = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x,axis=1))(vm) # normalise to unit length\n",
    "\n",
    "# forward pass in userNN\n",
    "input_user = tf.keras.Input(shape=(user_train.shape[1],))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.keras.layers.Lambda(lambda x: tf.linalg.l2_normalize(x,axis=1))(vu) # normalise to unit length\n",
    "\n",
    "# dot product\n",
    "output = tf.keras.layers.Dot(axes=1)([vm,vu])\n",
    "\n",
    "# build model\n",
    "model = tf.keras.Model([input_movie,input_user],output)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2d0e8432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9205\n",
      "Epoch 2/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9199\n",
      "Epoch 3/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9194\n",
      "Epoch 4/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9191\n",
      "Epoch 5/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9188\n",
      "Epoch 6/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9185\n",
      "Epoch 7/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9183\n",
      "Epoch 8/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9182\n",
      "Epoch 9/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9180\n",
      "Epoch 10/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9179\n",
      "Epoch 11/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9178\n",
      "Epoch 12/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9176\n",
      "Epoch 13/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9175\n",
      "Epoch 14/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.9174\n",
      "Epoch 15/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9174\n",
      "Epoch 16/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9173\n",
      "Epoch 17/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9172\n",
      "Epoch 18/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9171\n",
      "Epoch 19/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9171\n",
      "Epoch 20/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9170\n",
      "Epoch 21/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9169\n",
      "Epoch 22/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9169\n",
      "Epoch 23/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9168\n",
      "Epoch 24/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9167\n",
      "Epoch 25/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9167\n",
      "Epoch 26/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9166\n",
      "Epoch 27/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9166\n",
      "Epoch 28/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9165\n",
      "Epoch 29/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - loss: 0.9165\n",
      "Epoch 30/30\n",
      "\u001b[1m2500/2500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.9164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e12d3dd340>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will compile the model with squared error loss cost function and no regularisation\n",
    "model.compile(loss=tf.keras.losses.MeanSquaredError(),\n",
    "              optimizer=tf.keras.optimizers.Adam(0.01)) # unusually high lr seems to work\n",
    "\n",
    "# fit model\n",
    "model.fit([movie_train,user_train],targets_train[...,np.newaxis],epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "261d2507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.9245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9244731664657593"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([movie_test,user_test],targets_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7991b5",
   "metadata": {},
   "source": [
    "Comparable with training loss so this suggests overfitting has not occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "07bfe161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "tf.keras.models.save_model(model,\"models/content_based/lr1e-2_epoch30.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1826cf",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "30f36822",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cleaned_data/movie_dict.pkl\",\"rb\") as f: \n",
    "    movie_dict = pickle.load(f)\n",
    "\n",
    "movie_vecs = np.load(\"cleaned_data/movie_vecs.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "69404f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# make predictions for a particular user\n",
    "\n",
    "# get random idx\n",
    "random_idx = np.random.randint(0,user_train.shape[0])\n",
    "\n",
    "# get user vec\n",
    "user_vec = user_train[random_idx]\n",
    "\n",
    "# tile vector 1682 times because there are 1682 movies to predict ratings for\n",
    "user_vec=np.tile(user_vec,(len(movie_vecs),1))\n",
    "\n",
    "# scale movie vecs\n",
    "movie_vecs_scaled = scalerMovies.transform(movie_vecs)\n",
    "\n",
    "# make predictions\n",
    "p_unscaled = model.predict([movie_vecs_scaled,user_vec])\n",
    "p = scalerTargets.inverse_transform(p_unscaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "39189ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions standard deviation:  2.3093013e-07\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions standard deviation: \",p.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd73f34",
   "metadata": {},
   "source": [
    "My model is predicting the same rating (more or less) for every movie. This could mean one of a few things:\n",
    "- My movie feature vectors are too similar\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f41c9",
   "metadata": {},
   "source": [
    "# Improvements to Make\n",
    "- User feature vectors can be enriched by included user zip codes as input features in the user network. It is likely users that live in close proximity have similar movie taste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00db327",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
